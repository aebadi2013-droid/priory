{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e42a93-83d3-4342-9520-d0d62f5bd52c",
   "metadata": {},
   "source": [
    "Importing my development version of ShadowGrouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "540c584d-2a7a-4e62-a45b-8b2c24f0d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, numpy as np, time, pickle\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "from os import mkdir\n",
    "from os.path import isdir\n",
    "\n",
    "# adding ShadowGrouping package to the system path\n",
    "# SG_package_path = r\"G:\\\\My Drive\\\\Work\\\\Research\\\\Numerics\\\\ShadowGrouping Code\\\\\"\n",
    "SG_package_path = r\"C:\\Users\\aebad\\shadowgrouping\\\\\"\n",
    "sys.path.insert(0, SG_package_path)\n",
    "savename = \"_{}_.txt\" # insert {mapping_name}\n",
    "savepath = \"generated_data/\"\n",
    "\n",
    "# defining path where Hamiltonians are stored\n",
    "folder_Hamiltonians = SG_package_path + \"Hamiltonians_v2\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a412a400-182d-4483-ba9c-54ce54112f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shadowgrouping_v2.measurement_schemes import L1_sampler, Derandomization\n",
    "from shadowgrouping.measurement_schemes import Shadow_Grouping\n",
    "from shadowgrouping.measurement_schemes_Shadowupdate import (\n",
    "    Shadow_Grouping_Update, Shadow_Grouping_Update2, Shadow_Grouping_Update3, Shadow_Grouping_Update4, \n",
    "    Priori, Posteriori, Shadow_Grouping_Update8, Shadow_Grouping_Update9, \n",
    "    Shadow_Grouping_Update10, Shadow_Grouping_Update11, Shadow_Grouping_Update12, Shadow_Grouping_Update13)\n",
    "from shadowgrouping_v2.weight_functions import Bernstein_bound\n",
    "from shadowgrouping_v2.energy_estimator import Energy_estimator, StateSampler, Sign_estimator\n",
    "from shadowgrouping_v2.helper_functions import (\n",
    "    setting_to_str, char_to_int, int_to_char, settings_to_dict, prepare_settings_for_numba,\n",
    "    sample_obs_from_setting, setting_to_str, setting_to_obs_form, sample_obs_batch_from_setting_batch, sample_obs_batch_from_setting_batch_numba, bootstrap_rmse)\n",
    "from shadowgrouping_v2.hamiltonian import get_pauli_list, get_groundstate, mappings, load_pauli_list\n",
    "from shadowgrouping_v2.guarantees import (\n",
    "    get_epsilon_Bernstein, get_epsilon_Bernstein_no_restricted_validity, \n",
    "    get_epsilon_Bernstein_tighter, get_epsilon_Bernstein_tighter_no_restricted_validity, \n",
    "    get_epsilon_Bernstein_scalar, get_epsilon_Bernstein_scalar_no_restricted_validity,\n",
    "    get_epsilon_Bernstein_scalar_tighter, get_epsilon_Bernstein_scalar_tighter_no_restricted_validity, \n",
    "    get_epsilon_Hoeffding_scalar, get_epsilon_Hoeffding_scalar_tighter, get_epsilon_Chebyshev_scalar, \n",
    "    get_epsilon_Chebyshev_scalar_tighter, get_epsilon_single_Hoeffding_plus_union_bound,\n",
    "    get_epsilon_Chebyshev_scalar_numba, get_epsilon_Chebyshev_scalar_tighter_numba,\n",
    "    get_epsilon_Hoeffding_scalar_numba, get_epsilon_Hoeffding_scalar_tighter_numba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84655f21-2d26-438d-8893-6ce6a2e12d02",
   "metadata": {},
   "source": [
    "Choosing molecule, basis set and fermion-to-qubit mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48030974-dca8-4773-96af-f8eeb4738bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule_name = \"BeH2\" # choose one out of the molecules ['H2', 'H2_6-31g', 'LiH', 'BeH2', 'H2O', 'NH3']\n",
    "mapping_name = \"JW\" # choose one out of [\"JW\",\"BK\",\"Parity\"]\n",
    "if molecule_name == 'H2':\n",
    "    basis_set = \"6-31g\"\n",
    "else:\n",
    "    basis_set = \"sto3g\"\n",
    "num_qubits = {'H2': 8, 'LiH': 12, 'BeH2': 14, 'H2O': 14, \"NH3\": 16} # number of qubits in which Hamiltonian is defined\n",
    "savename = molecule_name + \"_molecule_\" + mapping_name + \"_\" + basis_set + savename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412affd-acb8-409e-9caf-141d75ff76e1",
   "metadata": {},
   "source": [
    "Obtaining Pauli decomposition of Hamiltonian and its exact ground state from saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfca54ad-40c8-4d20-ada5-c214b11ab0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Hamiltonian\n",
    "observables, w, offset, E_GS, state = load_pauli_list(folder_Hamiltonians,molecule_name,basis_set,mapping_name,diagonalize=False)\n",
    "\n",
    "# loading exact ground state\n",
    "path_to_GS = folder_Hamiltonians + molecule_name + \"_\" + basis_set + \"_\" + str(num_qubits[molecule_name]) + \"qubits\\\\exact_gs.txt\"\n",
    "with open(path_to_GS, 'r') as f:\n",
    "    data_string = f.read()\n",
    "state = data_string.split('\\n')\n",
    "state = state[:len(state)-1]\n",
    "for i in range(len(state)):\n",
    "    state[i] = complex(state[i])\n",
    "state = np.array(state)\n",
    "\n",
    "# Loading exact ground state energy\n",
    "path_to_GS_energy = folder_Hamiltonians + molecule_name + \"_\" + basis_set + \"_\" + str(num_qubits[molecule_name]) + \"qubits\\\\exact_gs_energy.txt\"\n",
    "with open(path_to_GS_energy, 'r') as f:\n",
    "    data_string = f.read()\n",
    "E_GS = float(data_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e2c3b8-a6bd-4fb6-ba64-b1cbb53c5513",
   "metadata": {},
   "source": [
    "Printing the number of observables and the total number of settings in the full scheme saved in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f95cc535-d517-473b-ba8d-1a1aa32bdaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observables:  665\n",
      "Number of qubits 14\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observables: \", len(observables))\n",
    "print(\"Number of qubits\",num_qubits[molecule_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a1ea4-2039-443d-b1ff-0e7b42ce4a56",
   "metadata": {},
   "source": [
    "Defining state sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9927022-d1d5-4b9a-ad66-f6314d56d99f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pppp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pppp\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pppp' is not defined"
     ]
    }
   ],
   "source": [
    "pppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89497cc0-f3d0-4e61-82d5-4418d0dceb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"n = 2 # num_qubits[molecule_name]\n",
    "state_rand = np.random.rand(2**num_qubits[molecule_name],) + 1j*np.random.rand(2**num_qubits[molecule_name],)\n",
    "state_rand = 1/np.linalg.norm(state_rand) * state_rand\n",
    "print(state_rand)\n",
    "state_sampler = StateSampler(state_rand)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a49263-6844-4a91-9758-217800d6537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_sampler = StateSampler(state)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e029f071-5ca3-4c60-ad78-56c41ff6bb2d",
   "metadata": {},
   "source": [
    "Initializing 'method' that will generate measurement scheme to estimate the energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629835ac-5349-45ee-a706-99b22184e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nreps = 100\n",
    "eps = 0.1\n",
    "alpha = np.max(np.abs(w))/np.min(np.abs(w)) + np.min(np.abs(w))\n",
    "#alpha = 1\n",
    "method = Shadow_Grouping(observables,w,eps,Bernstein_bound(alpha=alpha)())\n",
    "#method = Priori(observables,w,eps,Bernstein_bound(alpha=alpha)()) #based on gaurantee, epsilon v1, shadowgrouping till Nhits != 0, select only cliques which lead to complete setting\n",
    "#method = Posteriori(observables,w,eps,Bernstein_bound(alpha=alpha)()) #based on gaurantee, epsilon v1, shadowgrouping till Nhits != 0, select only cliques which lead to complete setting\n",
    "#method = Shadow_Grouping_Update77(observables,w,eps,Bernstein_bound(alpha=alpha)()) #based on gaurantee, epsilon v1, shadowgrouping till Nhits != 0, select only cliques which lead to complete setting\n",
    "estimator = Energy_estimator(method,state_sampler,offset=offset,N_reps_exp=Nreps)\n",
    "estimator.reset()\n",
    "print(\"value of alpha is\",alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc899d6-a3c7-4282-ba0e-41d5b86ca622",
   "metadata": {},
   "source": [
    "Adding measurement scheme to estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4377a-8961-4108-b05f-7d73017d1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating from scratch\n",
    "Nrounds = 1000\n",
    "t_1 = time.time()\n",
    "estimator.reset()\n",
    "num_points = 1\n",
    "rmse_values = []\n",
    "rmse_stds = []\n",
    "#estimator.propose_next_settings(Nrounds)\n",
    "for i in range(num_points):\n",
    "    estimator.propose_next_settings(Nrounds//1)\n",
    "    \"\"\"estimator.clear_outcomes()\n",
    "    n = 2 # num_qubits[molecule_name]\n",
    "    state_rand = np.random.rand(2**num_qubits[molecule_name],) + 1j*np.random.rand(2**num_qubits[molecule_name],)\n",
    "    state_rand = 1/np.linalg.norm(state_rand) * state_rand\n",
    "    print(state_rand)\n",
    "    estimator.state = StateSampler(state_rand)\"\"\"\n",
    "    estimator.measure_and_get_running_avgs()\n",
    "    energy_estimates = estimator.get_energy()\n",
    "    \"\"\"temp = abs(np.array(energy_estimates) - E_GS)**2\n",
    "    MSE_value = np.mean(temp)\n",
    "    MSE_std = np.std(temp) \n",
    "    RMSE_value = np.sqrt(MSE_value)\n",
    "    RMSE_std = np.sqrt(MSE_std)\n",
    "    rmse_values.append(RMSE_value)\n",
    "    rmse_stds.append(RMSE_std)\n",
    "    print(f\"Shots: {i} | RMSE: {RMSE_value:.6f} | Std: {RMSE_std:.6f}\")\"\"\"\n",
    "    rmse, rmse_se, (ci_lo, ci_hi), boot_vals = bootstrap_rmse(\n",
    "    energy_estimates, E_GS, n_boot=20000, ci=0.67)\n",
    "    rmse_values.append(rmse)\n",
    "    rmse_stds.append(rmse_se)\n",
    "    print(f\"Shots: {i} | RMSE: {rmse:.6f} | Std: {rmse_se:.6f}\")\n",
    "\n",
    "t_2 = time.time()\n",
    "#print(estimator.measurement_scheme.settings_dict) 22222222\n",
    "print(estimator.settings_dict)\n",
    "print(\"Elapsed time in seconds: \", t_2 - t_1)\n",
    "print(\"RMSE values\", rmse_values)\n",
    "print(\"RMSE STD\", rmse_stds)\n",
    "#print(\"average RMSE\", np.mean(rmse_values))\n",
    "#print(\"average STD\", np.mean(rmse_stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b95f9-3a6a-458f-9026-27aca379a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ------------------ Paths ------------------\n",
    "save_dir = os.path.join(savepath, \"epsilon_plots\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "log_path = os.path.join(\n",
    "    save_dir,\n",
    "    savename.format(\"all_methods\").replace(\".txt\", \"\") + \"_log.txt\"\n",
    ")\n",
    "\n",
    "# ------------------ Save current method results ------------------\n",
    "clean_method = str(method).split('.')[-1].split(' ')[0].replace('<', '').replace('>', '')\n",
    "\n",
    "with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"# METHOD: {clean_method}\\n\")\n",
    "    f.write(f\"# Nshots: {Nrounds}\\n\")\n",
    "    for r, v in zip(estimator.measurement_scheme.rounds,\n",
    "                    estimator.measurement_scheme.eps_values_v3):\n",
    "        f.write(f\"{r}\\t{v}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "print(f\"Appended results for method '{clean_method}' to {log_path}\")\n",
    "\n",
    "# ------------------ Keep only newest block per method ------------------\n",
    "def keep_latest_per_method_inplace(log_path: str) -> None:\n",
    "    \"\"\"Rewrite log so only the latest block per method remains.\"\"\"\n",
    "    if not os.path.exists(log_path):\n",
    "        return\n",
    "\n",
    "    with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    blocks = []  # (method, start_idx, end_idx)\n",
    "    current_method, start_idx = None, None\n",
    "\n",
    "    def close_block(end_idx):\n",
    "        nonlocal current_method, start_idx\n",
    "        if current_method is not None and start_idx is not None:\n",
    "            blocks.append((current_method, start_idx, end_idx))\n",
    "        current_method, start_idx = None, None\n",
    "\n",
    "    for i, raw in enumerate(lines):\n",
    "        line = raw.strip()\n",
    "        if line.startswith(\"# METHOD:\"):\n",
    "            close_block(i)\n",
    "            current_method = raw.split(\":\", 1)[1].strip()\n",
    "            start_idx = i\n",
    "        elif line == \"\" and current_method is not None:\n",
    "            close_block(i + 1)\n",
    "    close_block(len(lines))\n",
    "\n",
    "    if not blocks:\n",
    "        return\n",
    "\n",
    "    # keep only latest occurrence for each method\n",
    "    last_idx = {}\n",
    "    for idx, (m, _, _) in enumerate(blocks):\n",
    "        last_idx[m] = idx\n",
    "\n",
    "    kept_blocks = [blocks[i][1:] for i in sorted(last_idx.values(), key=lambda x: blocks[x][1])]\n",
    "    new_lines = []\n",
    "    for s, e in kept_blocks:\n",
    "        if new_lines and new_lines[-1].strip() != \"\":\n",
    "            new_lines.append(\"\\n\")\n",
    "        new_lines.extend(lines[s:e])\n",
    "    if new_lines and not new_lines[-1].endswith(\"\\n\"):\n",
    "        new_lines[-1] += \"\\n\"\n",
    "\n",
    "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(new_lines)\n",
    "\n",
    "keep_latest_per_method_inplace(log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cbefc8-91e8-4b6b-bf3a-5dfc345bc1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Read all results from file ------------------\n",
    "data = defaultdict(lambda: {\"rounds\": [], \"vals\": []})\n",
    "current_method = None\n",
    "\n",
    "with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\"# METHOD:\"):\n",
    "            current_method = line.split(\":\", 1)[1].strip()\n",
    "        elif line.startswith(\"#\"):\n",
    "            continue\n",
    "        elif current_method is not None:\n",
    "            try:\n",
    "                r_str, v_str = line.split()\n",
    "                data[current_method][\"rounds\"].append(float(r_str))\n",
    "                data[current_method][\"vals\"].append(float(v_str))\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "# ------------------ Plot all methods ------------------\n",
    "\"\"\"plt.figure(\"Epsilon evolution\", clear=True)\n",
    "for m, series in data.items():\n",
    "    if series[\"rounds\"]:\n",
    "        plt.plot(series[\"rounds\"], series[\"vals\"], label=m)\n",
    "\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(r\"$\\epsilon$\")\n",
    "plt.title(\"Epsilon evolution over rounds\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "#plt.xlim(200, max(series[\"rounds\"]))\n",
    "plt.yscale('log')\n",
    "#plt.xscale('log')\n",
    "\n",
    "combined_plot = os.path.join(\n",
    "    save_dir,\n",
    "    savename.format(\"combined_from_log\").replace(\".txt\", \"\") + f\"Nshots={Nrounds}.png\"\n",
    ")\n",
    "plt.savefig(combined_plot, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Combined epsilon plot saved to {combined_plot}\")\n",
    "\n",
    "plt.show()\"\"\"\n",
    "\n",
    "\n",
    "# ------------------ Plot all methods ------------------\n",
    "plt.figure(\"Epsilon evolution\", clear=True)\n",
    "for m, series in data.items():\n",
    "    if series[\"rounds\"]:\n",
    "        x = series[\"rounds\"]\n",
    "        y = series[\"vals\"]\n",
    "\n",
    "        # ✅ keep only points where x > 200\n",
    "        x_filtered = [xv for xv, yv in zip(x, y) if xv > 0]\n",
    "        y_filtered = [yv for xv, yv in zip(x, y) if xv > 0]\n",
    "\n",
    "        # Only plot if something remains\n",
    "        if x_filtered:\n",
    "            plt.plot(x_filtered, y_filtered, label=m)\n",
    "\n",
    "plt.xlabel(\"Round\")\n",
    "#plt.ylabel(r\"$\\epsilon$\")\n",
    "plt.ylabel(\"Upper Bound on Energy Deviation\")\n",
    "#plt.title(\"Epsilon evolution over rounds\")\n",
    "#plt.legend()\n",
    "plt.grid(True)\n",
    "plt.yscale('log')  # if you're using log scale\n",
    "\n",
    "combined_plot = os.path.join(\n",
    "    save_dir,\n",
    "    savename.format(\"combined_from_log\").replace(\".txt\", \"\") + f\"Nshots={Nrounds}.png\"\n",
    ")\n",
    "plt.savefig(combined_plot, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Combined epsilon plot saved to {combined_plot}\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f8c35-2cdd-4543-b450-e388d5492de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# ------------------ Plot all methods ------------------\n",
    "plt.figure(\"Epsilon evolution\", clear=True)\n",
    "\n",
    "# Set global style parameters\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 14,\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"legend.fontsize\": 14,\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    \"lines.linewidth\": 3\n",
    "})\n",
    "\n",
    "# ------------------ Fixed color order ------------------\n",
    "colors = [\n",
    "    \"#2ca02c\",  # green\n",
    "    \"#ff7f0e\",  # orange\n",
    "    \"#1f77b4\",  # blue\n",
    "    \"#d62728\",  # red\n",
    "    \"#9467bd\",  # purple\n",
    "    \"#8c564b\",  # brown\n",
    "    \"#e377c2\",  # pink\n",
    "    \"#7f7f7f\",  # gray\n",
    "    \"#bcbd22\",  # olive\n",
    "    \"#17becf\"   # cyan\n",
    "]\n",
    "color_cycle = iter(colors)\n",
    "\n",
    "# Different line styles\n",
    "line_styles = ['-.', '--', ':', '-' , 'dotted']\n",
    "style_cycle = iter(line_styles)\n",
    "\n",
    "# ------------------ Plot each method ------------------\n",
    "for m, series in data.items():\n",
    "    if series[\"rounds\"]:\n",
    "        x = series[\"rounds\"]\n",
    "        y = series[\"vals\"]\n",
    "\n",
    "        # Filter x > 0\n",
    "        x_filtered = [xv for xv, yv in zip(x, y) if xv > 0]\n",
    "        y_filtered = [yv for xv, yv in zip(x, y) if xv > 0]\n",
    "\n",
    "        if x_filtered:\n",
    "            label = \"ShadowGrouping\" if m == \"Shadow_Grouping\" else m\n",
    "            plt.plot(\n",
    "                x_filtered,\n",
    "                y_filtered,\n",
    "                linestyle=next(style_cycle),\n",
    "                color=next(color_cycle),   # ← fixed ordered colors\n",
    "                label=label\n",
    "            )\n",
    "\n",
    "# Axes and formatting\n",
    "plt.xlabel(\"Number of Measurement Rounds\")\n",
    "plt.ylabel(\"Upper Bound on Energy Deviation\")\n",
    "plt.legend(frameon=False)\n",
    "plt.grid(False)\n",
    "plt.yscale('log')\n",
    "\n",
    "# Save plot\n",
    "combined_plot = os.path.join(\n",
    "    save_dir,\n",
    "    savename.format(\"combined_from_log\").replace(\".txt\", \"\") + f\"Nshots={Nrounds}.png\"\n",
    ")\n",
    "plt.savefig(combined_plot, dpi=300, bbox_inches=\"tight\")\n",
    "print(f\"Combined epsilon plot saved to {combined_plot}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa57f96-afc0-40a3-bc39-7b354c34c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse, rmse_se, (ci_lo, ci_hi), boot_vals = bootstrap_rmse(\n",
    "    energy_estimates, E_GS, n_boot=20000, ci=0.67)\n",
    "print(f\"RMSE = {rmse:.6g} ± {rmse_se:.6g} (bootstrap SE)\")\n",
    "print(f\"67% percentile CI for RMSE: [{ci_lo:.6g}, {ci_hi:.6g}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d1a2f4-cc13-4d63-ab02-e29117028436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "# ------------------ Style ------------------\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 14,\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"axes.titlesize\": 14,\n",
    "    \"legend.fontsize\": 13,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"lines.linewidth\": 3\n",
    "})\n",
    "\n",
    "# ------------------ Ordered Color Palette (Editable) ------------------\n",
    "colors = [\n",
    "    \"#ff7f0e\",  # orange\n",
    "    \"#1f77b4\",  # blue\n",
    "    \"#2ca02c\",  # green\n",
    "    \"#9467bd\",  # purple\n",
    "    \"#17becf\",  # cyan\n",
    "    \"#d62728\",  # red\n",
    "]\n",
    "\n",
    "# ------------------ Patterns ------------------\n",
    "style_cycle = itertools.cycle(['--', ':', '-.', ':'])\n",
    "color_cycle = itertools.cycle(colors)\n",
    "\n",
    "method_style = {}  # method → (color, linestyle)\n",
    "\n",
    "def pretty_label(name: str) -> str:\n",
    "    if name == \"Shadow_Grouping\":\n",
    "        return \"ShadowGrouping\"\n",
    "    return name.replace(\"-\", \"\")\n",
    "\n",
    "# ------------------ Figure ------------------\n",
    "fig, ax = plt.subplots(figsize=(9.5, 6.5), constrained_layout=True)\n",
    "\n",
    "# Plot main curves\n",
    "for m, series in data.items():\n",
    "    if not series[\"rounds\"]:\n",
    "        continue\n",
    "\n",
    "    x = series[\"rounds\"]\n",
    "    y = series[\"vals\"]\n",
    "\n",
    "    if m not in method_style:\n",
    "        method_style[m] = (next(color_cycle), next(style_cycle))\n",
    "\n",
    "    color, ls = method_style[m]\n",
    "    ax.plot(x, y, color=color, linestyle=ls, label=pretty_label(m))\n",
    "\n",
    "ax.set_xlabel(\"Number of Measurement Rounds\")\n",
    "ax.set_ylabel(\"Upper Bound on Energy Deviation\")\n",
    "ax.set_yscale('log')\n",
    "ax.grid(False)\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "# Global x range\n",
    "all_x = [xx for s in data.values() for xx in s[\"rounds\"]]\n",
    "x_min, x_max = min(all_x), max(all_x)\n",
    "\n",
    "# ------------------ INSET 1 (Zoom < 200) ------------------\n",
    "inset1 = ax.inset_axes([0.10, 0.55, 0.38, 0.38])  # left-top\n",
    "for m, series in data.items():\n",
    "    x = series[\"rounds\"]\n",
    "    y = series[\"vals\"]\n",
    "    xf = [xx for xx in x if xx < 200]\n",
    "    yf = [yy for xx, yy in zip(x, y) if xx < 200]\n",
    "    if xf:\n",
    "        color, ls = method_style[m]\n",
    "        inset1.plot(xf, yf, color=color, linestyle=ls)\n",
    "\n",
    "inset1.set_xlim(x_min, min(200, x_max))\n",
    "inset1.set_yscale(\"log\")\n",
    "inset1.grid(False)\n",
    "inset1.tick_params(labelsize=9)\n",
    "for spine in inset1.spines.values():\n",
    "    spine.set_linewidth(1.1)\n",
    "inset1.set_yticks([])\n",
    "inset1.set_ylabel(\"\")\n",
    "inset1.tick_params(axis='y', which='both', length=0, labelleft=False)\n",
    "# ------------------ INSET 2 (Zoom > 900) ------------------\n",
    "if x_max > 900:\n",
    "    inset2 = ax.inset_axes([0.58, 0.10, 0.38, 0.38])  # right-bottom\n",
    "    for m, series in data.items():\n",
    "        x = series[\"rounds\"]\n",
    "        y = series[\"vals\"]\n",
    "        xf = [xx for xx in x if xx > 900]\n",
    "        yf = [yy for xx, yy in zip(x, y) if xx > 900]\n",
    "        if xf:\n",
    "            color, ls = method_style[m]\n",
    "            inset2.plot(xf, yf, color=color, linestyle=ls)\n",
    "\n",
    "    inset2.set_xlim(900, x_max)\n",
    "    inset2.set_yscale(\"log\")\n",
    "    inset2.grid(False)\n",
    "    inset2.tick_params(labelsize=9)\n",
    "    for spine in inset2.spines.values():\n",
    "        spine.set_linewidth(1.1)\n",
    "    inset2.set_yticks([])\n",
    "    inset2.set_ylabel(\"\")\n",
    "    inset2.tick_params(axis='y', which='both', length=0, labelleft=False)\n",
    "# ------------------ Save & Show ------------------\n",
    "combined_plot = os.path.join(\n",
    "    save_dir,\n",
    "    savename.replace(\".txt\", \"\").format(\"combined_from_log\") + f\"Nshots={Nrounds}.png\"\n",
    ")\n",
    "\n",
    "fig.savefig(combined_plot, dpi=300)  # no bbox_inches=\"tight\" → no renderer bugs\n",
    "print(f\"Saved: {combined_plot}\")\n",
    "\n",
    "plt.show()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c347e1-7cbb-482a-b77a-2ce3fd64248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823969e-13cc-47c8-9446-6b3b32570b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# ------------------ Paths ------------------\n",
    "save_dir = os.path.join(savepath, \"gaurantee_plots\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "log_path = os.path.join(\n",
    "    save_dir,\n",
    "    savename.format(\"all_methods\").replace(\".txt\", \"\") + \"_log.txt\"\n",
    ")\n",
    "\n",
    "# ------------------ Save current method results ------------------\n",
    "clean_method = str(method).split('.')[-1].split(' ')[0].replace('<', '').replace('>', '')\n",
    "\n",
    "with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"# METHOD: {clean_method}\\n\")\n",
    "    f.write(f\"# Nshots: {Nrounds}\\n\")\n",
    "    for r, v in zip(estimator.measurement_scheme.rounds,\n",
    "                    estimator.measurement_scheme.provablegaurantee):\n",
    "        f.write(f\"{r}\\t{v}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "print(f\"Appended results for method '{clean_method}' to {log_path}\")\n",
    "\n",
    "# ------------------ Keep only newest block per method (in place) ------------------\n",
    "def keep_latest_per_method_inplace(path: str) -> None:\n",
    "    \"\"\"\n",
    "    Rewrite `path` so only the latest block per method remains.\n",
    "    Block format:\n",
    "      # METHOD: <name>\n",
    "      # Nshots: <...>\n",
    "      <round>\\t<value>\n",
    "      ...\n",
    "      <blank line> (optional at EOF)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        return\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    blocks = []  # (method, start_idx, end_idx)\n",
    "    current_method, start_idx = None, None\n",
    "\n",
    "    def close_block(end_idx: int):\n",
    "        nonlocal current_method, start_idx\n",
    "        if current_method is not None and start_idx is not None:\n",
    "            blocks.append((current_method, start_idx, end_idx))\n",
    "        current_method, start_idx = None, None\n",
    "\n",
    "    for i, raw in enumerate(lines):\n",
    "        s = raw.strip()\n",
    "        if s.startswith(\"# METHOD:\"):\n",
    "            close_block(i)\n",
    "            current_method = raw.split(\":\", 1)[1].strip()\n",
    "            start_idx = i\n",
    "        elif s == \"\" and current_method is not None:\n",
    "            close_block(i + 1)\n",
    "    close_block(len(lines))  # flush last block if file ended without blank line\n",
    "\n",
    "    if not blocks:\n",
    "        return\n",
    "\n",
    "    # keep only the last occurrence for each method\n",
    "    last_idx_for_method = {}\n",
    "    for idx, (m, _, _) in enumerate(blocks):\n",
    "        last_idx_for_method[m] = idx  # overwrite => last wins\n",
    "\n",
    "    keep_indices = sorted(last_idx_for_method.values(), key=lambda i: blocks[i][1])\n",
    "    kept_spans = [(blocks[i][1], blocks[i][2]) for i in keep_indices]\n",
    "\n",
    "    new_lines = []\n",
    "    for s, e in kept_spans:\n",
    "        if new_lines and new_lines[-1].strip() != \"\":\n",
    "            new_lines.append(\"\\n\")\n",
    "        new_lines.extend(lines[s:e])\n",
    "\n",
    "    if new_lines and not new_lines[-1].endswith(\"\\n\"):\n",
    "        new_lines[-1] += \"\\n\"\n",
    "\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(new_lines)\n",
    "\n",
    "# Deduplicate log now\n",
    "keep_latest_per_method_inplace(log_path)\n",
    "\n",
    "# ------------------ Read all results from (deduped) file ------------------\n",
    "data = defaultdict(lambda: {\"rounds\": [], \"vals\": []})\n",
    "current_method = None\n",
    "\n",
    "with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\"# METHOD:\"):\n",
    "            current_method = line.split(\":\", 1)[1].strip()\n",
    "        elif line.startswith(\"#\"):\n",
    "            continue\n",
    "        elif current_method is not None:\n",
    "            try:\n",
    "                r_str, v_str = line.split()\n",
    "                data[current_method][\"rounds\"].append(float(r_str))\n",
    "                data[current_method][\"vals\"].append(float(v_str))\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "# ------------------ Plot all methods (latest run only) ------------------\n",
    "plt.figure(\"Provable Guarantee evolution\", clear=True)\n",
    "for m, series in data.items():\n",
    "    if series[\"rounds\"]:\n",
    "        x = np.asarray(series[\"rounds\"], dtype=float)\n",
    "        y = np.asarray(series[\"vals\"], dtype=float)\n",
    "        order = np.argsort(x)  # ensure clean monotone x\n",
    "        plt.plot(x[order], y[order], label=m)  # no markers => no big dots\n",
    "\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Guarantee\")\n",
    "plt.title(\"Provable Guarantee over rounds\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "combined_plot = os.path.join(\n",
    "    save_dir,\n",
    "    savename.format(\"combined_from_log\").replace(\".txt\", \"\") + f\"Nshots={Nrounds}.png\"\n",
    ")\n",
    "plt.savefig(combined_plot, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Combined plot saved to {combined_plot}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f5920f-1cee-4421-ac44-dd8871042010",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of measurement rounds: ', estimator.num_settings)\n",
    "#print('Total number of distinct measurement settings: ', len(estimator.measurement_scheme.settings_dict)) 22222222\n",
    "print('Total number of distinct measurement settings: ', len(estimator.settings_dict))\n",
    "N_samples = np.sum(np.array(estimator.measurement_scheme.N_hits))\n",
    "print('Total number of samples across all observables: ', N_samples)\n",
    "print('Total number of observables: ', len(observables))\n",
    "print('Number of samples for each observable')\n",
    "print(estimator.measurement_scheme.N_hits)\n",
    "print('setting dictionary')\n",
    "#print(estimator.measurement_scheme.settings_dict) 2222222222\n",
    "print(estimator.settings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e13af9-cc1d-4222-a71c-0b339d2a8f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from os import mkdir\n",
    "from os.path import isdir\n",
    "\n",
    "# --- Global font size settings ---\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 16,\n",
    "    \"axes.labelsize\": 16,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"legend.fontsize\": 16,\n",
    "})\n",
    "\n",
    "# --- Filter settings with frequency >= 5 ---\n",
    "filtered_settings = {k: v for k, v in estimator.settings_dict.items() if v >= 5}\n",
    "\n",
    "# --- Sort by frequency (descending) ---\n",
    "sorted_settings = dict(sorted(filtered_settings.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Convert method to clean string for filename\n",
    "clean_method = str(method).split('.')[-1].split(' ')[0].replace('<', '').replace('>', '')\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(sorted_settings.keys(), sorted_settings.values(), color='skyblue')\n",
    "\n",
    "# Remove x-axis labels entirely\n",
    "plt.xticks([], [])  # no tick positions, no tick labels\n",
    "plt.xlabel(\"Distinct measurement settings\", fontsize=16)  # keep label size consistent\n",
    "plt.ylabel(\"Frequency of selection as the best setting\", fontsize=16)\n",
    "\n",
    "plt.yticks(fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "# --- Save plot ---\n",
    "if not isdir(savepath + \"bargraph/\"):\n",
    "    mkdir(savepath + \"bargraph/\")\n",
    "\n",
    "plot_filename = savepath + \"bargraph/\" + savename.format(clean_method).replace(\".txt\", \"\") + f\"Nshots={Nrounds}.png\"\n",
    "\n",
    "plt.savefig(plot_filename, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Measurement settings frequency saved to {plot_filename}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa0cc7f-1848-48b4-b5fc-f52ab0f6ea19",
   "metadata": {},
   "source": [
    "Computing the provable guarantees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fc8741-b579-472c-91ce-26d81bad217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.02\n",
    "\n",
    "#settings_int, settings_reps = prepare_settings_for_numba(estimator.measurement_scheme.settings_dict) 22222222\n",
    "settings_int, settings_reps = prepare_settings_for_numba(estimator.settings_dict)\n",
    "\n",
    "# Scalar Hoeffding guarantees\n",
    "epsilon_Hoeffding_scalar_original, _ = get_epsilon_Hoeffding_scalar_numba(delta, estimator.measurement_scheme.N_hits, estimator.measurement_scheme.w)\n",
    "print('Hoeffding scalar original: ', epsilon_Hoeffding_scalar_original)\n",
    "epsilon_Hoeffding_scalar_tighter, _ = get_epsilon_Hoeffding_scalar_tighter_numba(delta, estimator.measurement_scheme.N_hits, estimator.measurement_scheme.w, \n",
    "                                                                                 settings_int, settings_reps, estimator.measurement_scheme.obs)\n",
    "print('Hoeffding scalar tighter: ', epsilon_Hoeffding_scalar_tighter)\n",
    "# Scalar Chebyshev guarantees\n",
    "epsilon_Chebyshev_scalar_original, _ = get_epsilon_Chebyshev_scalar_numba(delta, estimator.measurement_scheme.N_hits, estimator.measurement_scheme.w)\n",
    "print('Chebyshev scalar original: ', epsilon_Chebyshev_scalar_original)\n",
    "epsilon_Chebyshev_scalar_tighter, _ = get_epsilon_Chebyshev_scalar_tighter_numba(delta, estimator.measurement_scheme.N_hits, estimator.measurement_scheme.w, \n",
    "                                                                                 settings_int, settings_reps, estimator.measurement_scheme.obs)\n",
    "print('Chebyshev scalar tighter: ', epsilon_Chebyshev_scalar_tighter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c88843b-912d-46b4-b6ae-5f6b4759a02d",
   "metadata": {},
   "source": [
    "Performing sampling over $N_{\\textrm{reps}}$ experiments (as defined above), each with N rounds (set above when defining scheme): Joint version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802615c-7f3d-4c73-afaa-e59aeb82f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_init = time.time()\n",
    "\n",
    "estimator.clear_outcomes()\n",
    "estimator.measure_and_get_running_avgs()\n",
    "energy_estimates = estimator.get_energy()\n",
    "\"\"\"temp = abs(np.array(energy_estimates) - E_GS)**2\n",
    "MSE_value = np.mean(temp)\n",
    "MSE_std = np.std(temp) \n",
    "RMSE_value = np.sqrt(MSE_value)\n",
    "RMSE_std = np.sqrt(MSE_std)\"\"\"\n",
    "\n",
    "rmse, rmse_se, (ci_lo, ci_hi), boot_vals = bootstrap_rmse(\n",
    "    energy_estimates, E_GS, n_boot=20000, ci=0.67)\n",
    "\n",
    "t_end = time.time()\n",
    "\n",
    "print(f\"RMSE: {rmse:.6f} \\u00B1 {rmse_se:.6f}\")\n",
    "print(\"Elapsed time in seconds: \", t_end - t_init)\n",
    "\n",
    "method_name = str(method).split('.')[-1].split(' ')[0].replace('<', '').replace('>', '')  # <-- Replace with the actual method name\n",
    "\n",
    "results = {method_name: (rmse, rmse_se)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2031a7-4591-4a9f-a9a7-d4c2e5f61fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epsilon_Chebyshev_scalar_tighter/rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06a0238-7727-483a-98e1-c538ce7165aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(energy_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec24cfd6-46f8-4a59-b3da-826a7a2fc1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimator.running_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58572e-802b-4cd1-8294-2e9296e2b437",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimator.running_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e2d504-cf1d-4b55-b97c-5e054bf134f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "# --- paths & labels ----------------------------------------------------------\n",
    "tab_dir = os.path.join(savepath, \"tab1\")\n",
    "os.makedirs(tab_dir, exist_ok=True)\n",
    "\n",
    "bar_dir = os.path.join(savepath, \"emprical\")\n",
    "os.makedirs(bar_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# MATCH ORIGINAL NAMING STYLE:\n",
    "# save_dict(savepath+\"tab1/\"+savename.format(mapping_name).replace(\".txt\",\"\")+f\"_Nshots={NUM_STEPS}.txt\",results)\n",
    "base_name = savename.format(clean_method).replace(\".txt\",\"\") + f\"Nshots={Nrounds}\"\n",
    "txt_path = os.path.join(tab_dir, base_name + \".txt\")\n",
    "plot_filename = os.path.join(bar_dir, base_name + \".png\")\n",
    "run_label = base_name  # used for grouping in plots\n",
    "\n",
    "# --- ensure TXT exists with header ------------------------------------------\n",
    "header = \"run_label\\tmethod\\trmse\\trmse_std\\tt_end_epoch\\tt_end_iso\\tnum_steps\"\n",
    "new_file = not os.path.isfile(txt_path)\n",
    "if new_file:\n",
    "    with open(txt_path, \"w\") as f:\n",
    "        f.write(header + \"\\n\")\n",
    "\n",
    "# --- append rows for current results ----------------------------------------\n",
    "# Expect: results = { \"MethodName\": (RMSE_value, RMSE_std), ... }\n",
    "now_iso = time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.localtime(t_end))\n",
    "with open(txt_path, \"a\") as f:\n",
    "    for method, (rmse, rmse_std) in results.items():\n",
    "        line = f\"{run_label}\\t{method}\\t{float(rmse)}\\t{float(rmse_std)}\\t{float(t_end)}\\t{now_iso}\\t{int(Nrounds)}\"\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"Saved {len(results)} row(s) to {txt_path}\")\n",
    "\n",
    "# --- read back entries for current run_label --------------------------------\n",
    "rows = []\n",
    "with open(txt_path, \"r\") as f:\n",
    "    next(f)  # skip header\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if parts[0] == run_label:\n",
    "            rows.append({\n",
    "                \"run_label\": parts[0],\n",
    "                \"method\": parts[1],\n",
    "                \"rmse\": float(parts[2]),\n",
    "                \"rmse_std\": float(parts[3]),\n",
    "                \"t_end_epoch\": float(parts[4]),\n",
    "                \"t_end_iso\": parts[5],\n",
    "                \"num_steps\": int(parts[6])\n",
    "            })\n",
    "\n",
    "# Keep the *latest* per method\n",
    "latest_by_method = OrderedDict()\n",
    "for row in rows:\n",
    "    latest_by_method[row[\"method\"]] = row\n",
    "\n",
    "methods = list(latest_by_method.keys())\n",
    "rmse_values = [latest_by_method[m][\"rmse\"] for m in methods]\n",
    "std_values  = [latest_by_method[m][\"rmse_std\"] for m in methods]\n",
    "\n",
    "# --- plot --------------------------------------------------------------------\n",
    "plt.figure(figsize=(7.5, 4.5))\n",
    "plt.bar(methods, rmse_values, yerr=std_values, capsize=5)\n",
    "plt.xlabel(\"Methods\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(f\"RMSE ± std for {run_label}\")\n",
    "plt.xticks(rotation=75, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(plot_filename, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Empirical benchmark: RMSE plot saved to {plot_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0afc08-9cde-47a8-b2a8-9da752d7d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Optional: set default font size to 16 globally\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 16,\n",
    "    \"axes.titlesize\": 16,\n",
    "    \"axes.labelsize\": 16,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"legend.fontsize\": 16,\n",
    "})\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Paths & naming (read-only)\n",
    "# ------------------------------------------------------------\n",
    "tab_dir   = os.path.join(savepath, \"RMSE\")\n",
    "bar_dir   = os.path.join(savepath, \"emprical\")\n",
    "os.makedirs(bar_dir, exist_ok=True)\n",
    "\n",
    "base_name  = savename.format(mapping_name).replace(\".txt\",\"\") + f\"Nshots={Nrounds}\"\n",
    "txt_path   = os.path.join(tab_dir, base_name + \".txt\")\n",
    "plot_path  = os.path.join(bar_dir, base_name + \".png\")\n",
    "run_label  = base_name\n",
    "\n",
    "base_root    = savename.format(mapping_name).replace(\".txt\",\"\")\n",
    "vs_txt_path  = os.path.join(tab_dir, base_root + \"_vs_Nshots.txt\")\n",
    "vs_plot_path = os.path.join(bar_dir, base_root + \"_RMSE_vs_Nshots.png\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Bar chart (READ ONLY, green–orange–blue colors)\n",
    "# ------------------------------------------------------------\n",
    "if not os.path.isfile(txt_path):\n",
    "    raise FileNotFoundError(f\"Per-run file not found: {txt_path}\")\n",
    "\n",
    "rows = []\n",
    "with open(txt_path, \"r\") as f:\n",
    "    next(f, None)\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) != 7:\n",
    "            continue\n",
    "        if parts[0] == run_label:\n",
    "            try:\n",
    "                rows.append({\n",
    "                    \"method\": parts[1],\n",
    "                    \"rmse\": float(parts[2]),\n",
    "                    \"rmse_std\": float(parts[3]),\n",
    "                })\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "# Keep latest per method\n",
    "latest_by_method = OrderedDict()\n",
    "for row in rows:\n",
    "    latest_by_method[row[\"method\"]] = row\n",
    "\n",
    "methods   = list(latest_by_method.keys())\n",
    "rmse_vals = [latest_by_method[m][\"rmse\"] for m in methods]\n",
    "rmse_stds = [latest_by_method[m][\"rmse_std\"] for m in methods]\n",
    "\n",
    "# Fixed colors: green, orange, blue\n",
    "bar_colors = ['#2ca02c', '#ff7f0e', '#1f77b4']\n",
    "colors = [bar_colors[i % len(bar_colors)] for i in range(len(methods))]\n",
    "\n",
    "plt.figure(figsize=(7.5, 4.5))\n",
    "plt.bar(methods, rmse_vals, yerr=rmse_stds, capsize=5, color=colors)\n",
    "plt.xlabel(\"Methods\", fontsize=16)\n",
    "plt.ylabel(\"RMSE\", fontsize=16)\n",
    "plt.xticks(rotation=75, ha=\"right\", fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.grid(False)  # No grid\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Empirical benchmark: RMSE bar plot saved to {plot_path}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) RMSE vs Number of Rounds (NO connecting lines; ensure ticks)\n",
    "# ------------------------------------------------------------\n",
    "if not os.path.isfile(vs_txt_path):\n",
    "    raise FileNotFoundError(f\"Accumulated file not found: {vs_txt_path}\")\n",
    "\n",
    "series = {}\n",
    "with open(vs_txt_path, \"r\") as f:\n",
    "    next(f, None)\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) != 7:\n",
    "            continue\n",
    "        run_root_i, method_i, nshots_i, rmse_i, std_i, _, _ = parts\n",
    "        if run_root_i != base_root:\n",
    "            continue\n",
    "        try:\n",
    "            nshots_i = int(nshots_i)\n",
    "            rmse_i   = float(rmse_i)\n",
    "            std_i    = float(std_i)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        series.setdefault(method_i, []).append(\n",
    "            {\"Nshots\": nshots_i, \"rmse\": rmse_i, \"rmse_std\": std_i}\n",
    "        )\n",
    "\n",
    "# Deduplicate and sort\n",
    "for m, pts in list(series.items()):\n",
    "    by_n = {}\n",
    "    for p in pts:\n",
    "        by_n[p[\"Nshots\"]] = p\n",
    "    series[m] = sorted(by_n.values(), key=lambda d: d[\"Nshots\"])\n",
    "\n",
    "plt.figure(figsize=(8.0, 5.0))\n",
    "\n",
    "for i, (method_i, pts) in enumerate(series.items()):\n",
    "    if not pts:\n",
    "        continue\n",
    "    xs = [p[\"Nshots\"] for p in pts]\n",
    "    ys = [p[\"rmse\"] for p in pts]\n",
    "    es = [p[\"rmse_std\"] for p in pts]\n",
    "\n",
    "    color = bar_colors[i % len(bar_colors)]\n",
    "    # Plot ONLY markers (no connecting lines)\n",
    "    plt.errorbar(xs, ys, yerr=es, fmt='o', capsize=4, markersize=7,\n",
    "                 label=method_i, color=color, linewidth=1.8)\n",
    "\n",
    "plt.xlabel(\"Number of measurement rounds\", fontsize=16)\n",
    "plt.ylabel(\"RMSE [Ha]\", fontsize=16)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "# Log scales\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "# No grid\n",
    "plt.grid(False)\n",
    "\n",
    "# Ensure visible major & minor tick marks\n",
    "plt.minorticks_on()\n",
    "plt.tick_params(axis='both', which='both', direction='in', length=6, width=1)\n",
    "\n",
    "plt.legend(title=\"Method\", ncol=1, fontsize=16, title_fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(vs_plot_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Empirical benchmark: RMSE-vs-rounds plot saved to {vs_plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc07ceb3-9aef-4084-b492-d42dd6642f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f135a639-ac0c-4a3c-b76b-7e29ace1e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Paths & naming (kept as in your script)\n",
    "# ------------------------------------------------------------\n",
    "tab_dir = os.path.join(savepath, \"RMSE\")\n",
    "os.makedirs(tab_dir, exist_ok=True)\n",
    "\n",
    "bar_dir = os.path.join(savepath, \"emprical\")\n",
    "os.makedirs(bar_dir, exist_ok=True)\n",
    "\n",
    "base_name  = savename.format(mapping_name).replace(\".txt\",\"\") + f\"Nshots={Nrounds}\"\n",
    "txt_path   = os.path.join(tab_dir, base_name + \".txt\")\n",
    "plot_path  = os.path.join(bar_dir, base_name + \".png\")\n",
    "run_label  = base_name\n",
    "\n",
    "base_root    = savename.format(mapping_name).replace(\".txt\",\"\")\n",
    "vs_txt_path  = os.path.join(tab_dir, base_root + \"_vs_Nshots.txt\")      # keeping existing file name for continuity\n",
    "vs_plot_path = os.path.join(bar_dir, base_root + \"_RMSE_vs_Nshots.png\") # keeping existing file name for continuity\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Write per-run TXT (append-safe)\n",
    "# ------------------------------------------------------------\n",
    "header = \"run_label\\tmethod\\trmse\\trmse_std\\tt_end_epoch\\tt_end_iso\\tnum_steps\"\n",
    "if not os.path.isfile(txt_path):\n",
    "    with open(txt_path, \"w\") as f:\n",
    "        f.write(header + \"\\n\")\n",
    "\n",
    "now_iso = time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.localtime(t_end))\n",
    "\n",
    "with open(txt_path, \"a\") as f:\n",
    "    for method, (rmse, rmse_std) in results.items():\n",
    "        line = f\"{run_label}\\t{method}\\t{float(rmse)}\\t{float(rmse_std)}\\t{float(t_end)}\\t{now_iso}\\t{int(Nrounds)}\"\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"Saved {len(results)} row(s) to {txt_path}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Bar chart (per-run)\n",
    "# ------------------------------------------------------------\n",
    "rows = []\n",
    "with open(txt_path, \"r\") as f:\n",
    "    next(f, None)\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) != 7:\n",
    "            continue\n",
    "        if parts[0] == run_label:\n",
    "            try:\n",
    "                rows.append({\n",
    "                    \"method\": parts[1],\n",
    "                    \"rmse\": float(parts[2]),\n",
    "                    \"rmse_std\": float(parts[3]),\n",
    "                })\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "latest_by_method = OrderedDict()\n",
    "for row in rows:\n",
    "    latest_by_method[row[\"method\"]] = row\n",
    "\n",
    "methods   = list(latest_by_method.keys())\n",
    "rmse_vals = [latest_by_method[m][\"rmse\"] for m in methods]\n",
    "rmse_stds = [latest_by_method[m][\"rmse_std\"] for m in methods]\n",
    "\n",
    "plt.figure(figsize=(7.5, 4.5))\n",
    "plt.bar(methods, rmse_vals, yerr=rmse_stds, capsize=5)\n",
    "plt.xlabel(\"Methods\", fontsize=14)\n",
    "plt.ylabel(\"RMSE\", fontsize=14)\n",
    "plt.xticks(rotation=75, ha=\"right\", fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Empirical benchmark: RMSE bar plot saved to {plot_path}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Accumulate across rounds for RMSE-vs-rounds plot\n",
    "# ------------------------------------------------------------\n",
    "vs_header = \"run_root\\tmethod\\tNshots\\trmse\\trmse_std\\tt_end_epoch\\tt_end_iso\"\n",
    "if not os.path.isfile(vs_txt_path):\n",
    "    with open(vs_txt_path, \"w\") as f:\n",
    "        f.write(vs_header + \"\\n\")\n",
    "\n",
    "with open(vs_txt_path, \"a\") as f:\n",
    "    for method, (rmse, rmse_std) in results.items():\n",
    "        f.write(f\"{base_root}\\t{method}\\t{int(Nrounds)}\\t{float(rmse)}\\t{float(rmse_std)}\\t{float(t_end)}\\t{now_iso}\\n\")\n",
    "\n",
    "print(f\"Appended {len(results)} row(s) to {vs_txt_path}\")\n",
    "\n",
    "# Build time series per method\n",
    "series = {}\n",
    "with open(vs_txt_path, \"r\") as f:\n",
    "    next(f, None)\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) != 7:\n",
    "            continue\n",
    "        run_root_i, method_i, nshots_i, rmse_i, std_i, _, _ = parts\n",
    "        if run_root_i != base_root:\n",
    "            continue\n",
    "        try:\n",
    "            nshots_i = int(nshots_i)\n",
    "            rmse_i   = float(rmse_i)\n",
    "            std_i    = float(std_i)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        series.setdefault(method_i, []).append(\n",
    "            {\"Nshots\": nshots_i, \"rmse\": rmse_i, \"rmse_std\": std_i}\n",
    "        )\n",
    "\n",
    "# Deduplicate by (method, Nshots): keep latest and sort\n",
    "for m, pts in list(series.items()):\n",
    "    by_n = {}\n",
    "    for p in pts:\n",
    "        by_n[p[\"Nshots\"]] = p\n",
    "    series[m] = sorted(by_n.values(), key=lambda d: d[\"Nshots\"])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Plot RMSE vs Number of Rounds (points only, no connecting lines)\n",
    "# ------------------------------------------------------------\n",
    "plt.figure(figsize=(8.0, 5.0))\n",
    "\n",
    "for method_i, pts in series.items():\n",
    "    if not pts:\n",
    "        continue\n",
    "    xs = [p[\"Nshots\"] for p in pts]\n",
    "    ys = [p[\"rmse\"] for p in pts]\n",
    "    es = [p[\"rmse_std\"] for p in pts]\n",
    "\n",
    "    # Plot only markers (no connecting lines)\n",
    "    plt.errorbar(xs, ys, yerr=es, fmt='o', linestyle='none', capsize=4,\n",
    "                 label=method_i, markersize=6)\n",
    "\n",
    "# Labels and ticks with font size 14\n",
    "plt.xlabel(\"Number of measurement rounds\", fontsize=14)\n",
    "plt.ylabel(\"RMSE [Ha]\", fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# No title\n",
    "# plt.title(f\"RMSE vs Number of rounds for {base_root}\")\n",
    "\n",
    "# Log scales and grid\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.grid(True, which=\"both\", axis=\"both\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Legend with font size 14\n",
    "plt.legend(title=\"Method\", ncol=1, fontsize=14, title_fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(vs_plot_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Empirical benchmark: RMSE-vs-rounds plot saved to {vs_plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a66302-7509-4bd6-8aa7-a84e909eb81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Paths & naming (matches your original naming convention)\n",
    "# ------------------------------------------------------------\n",
    "tab_dir = os.path.join(savepath, \"RMSE\")\n",
    "os.makedirs(tab_dir, exist_ok=True)\n",
    "\n",
    "bar_dir = os.path.join(savepath, \"emprical\")  # keeping your folder name\n",
    "os.makedirs(bar_dir, exist_ok=True)\n",
    "\n",
    "# Example original pattern:\n",
    "# save_dict(savepath+\"tab1/\"+savename.format(mapping_name).replace(\".txt\",\"\")+f\"_Nshots={NUM_STEPS}.txt\", results)\n",
    "base_name  = savename.format(mapping_name).replace(\".txt\",\"\") + f\"Nshots={Nrounds}\"\n",
    "txt_path   = os.path.join(tab_dir, base_name + \".txt\")\n",
    "plot_path  = os.path.join(bar_dir, base_name + \".png\")\n",
    "run_label  = base_name\n",
    "\n",
    "# Root name without the Nshots suffix, e.g. \"LiH_molecule_JW_empirical\"\n",
    "base_root       = savename.format(mapping_name).replace(\".txt\",\"\")\n",
    "vs_txt_path     = os.path.join(tab_dir, base_root + \"_vs_Nshots.txt\")\n",
    "vs_plot_path    = os.path.join(bar_dir, base_root + \"_RMSE_vs_Nshots.png\")\n",
    "powerfit_path   = os.path.join(tab_dir, base_root + \"_powerfit.txt\")  # stores A,c per method for N>1000\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Write per-run TXT (append-safe)\n",
    "# ------------------------------------------------------------\n",
    "header = \"run_label\\tmethod\\trmse\\trmse_std\\tt_end_epoch\\tt_end_iso\\tnum_steps\"\n",
    "if not os.path.isfile(txt_path):\n",
    "    with open(txt_path, \"w\") as f:\n",
    "        f.write(header + \"\\n\")\n",
    "\n",
    "now_iso = time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.localtime(t_end))\n",
    "\n",
    "with open(txt_path, \"a\") as f:\n",
    "    for method, (rmse, rmse_std) in results.items():\n",
    "        line = f\"{run_label}\\t{method}\\t{float(rmse)}\\t{float(rmse_std)}\\t{float(t_end)}\\t{now_iso}\\t{int(Nrounds)}\"\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"Saved {len(results)} row(s) to {txt_path}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Bar chart (per-run)\n",
    "# ------------------------------------------------------------\n",
    "# Read back only current run_label\n",
    "rows = []\n",
    "with open(txt_path, \"r\") as f:\n",
    "    next(f, None)\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) != 7:\n",
    "            continue\n",
    "        if parts[0] == run_label:\n",
    "            try:\n",
    "                rows.append({\n",
    "                    \"method\": parts[1],\n",
    "                    \"rmse\": float(parts[2]),\n",
    "                    \"rmse_std\": float(parts[3]),\n",
    "                })\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "# Keep latest per method\n",
    "latest_by_method = OrderedDict()\n",
    "for row in rows:\n",
    "    latest_by_method[row[\"method\"]] = row\n",
    "\n",
    "methods     = list(latest_by_method.keys())\n",
    "rmse_vals   = [latest_by_method[m][\"rmse\"] for m in methods]\n",
    "rmse_stds   = [latest_by_method[m][\"rmse_std\"] for m in methods]\n",
    "\n",
    "plt.figure(figsize=(7.5, 4.5))\n",
    "plt.bar(methods, rmse_vals, yerr=rmse_stds, capsize=5)\n",
    "plt.xlabel(\"Methods\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(f\"RMSE ± std for {run_label}\")\n",
    "plt.xticks(rotation=75, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Empirical benchmark: RMSE bar plot saved to {plot_path}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Accumulate across Nshots for RMSE-vs-Nshots plot\n",
    "# ------------------------------------------------------------\n",
    "# Ensure vs file exists with header\n",
    "vs_header = \"run_root\\tmethod\\tNshots\\trmse\\trmse_std\\tt_end_epoch\\tt_end_iso\"\n",
    "if not os.path.isfile(vs_txt_path):\n",
    "    with open(vs_txt_path, \"w\") as f:\n",
    "        f.write(vs_header + \"\\n\")\n",
    "\n",
    "# Append this run's results to the vs_Nshots file\n",
    "with open(vs_txt_path, \"a\") as f:\n",
    "    for method, (rmse, rmse_std) in results.items():\n",
    "        f.write(f\"{base_root}\\t{method}\\t{int(Nrounds)}\\t{float(rmse)}\\t{float(rmse_std)}\\t{float(t_end)}\\t{now_iso}\\n\")\n",
    "\n",
    "print(f\"Appended {len(results)} row(s) to {vs_txt_path}\")\n",
    "\n",
    "# Read back & build time series per method for this base_root\n",
    "series = {}  # method -> list of points dicts: {\"Nshots\", \"rmse\", \"rmse_std\"}\n",
    "with open(vs_txt_path, \"r\") as f:\n",
    "    next(f, None)\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) != 7:\n",
    "            continue\n",
    "        run_root_i, method_i, nshots_i, rmse_i, std_i, _, _ = parts\n",
    "        if run_root_i != base_root:\n",
    "            continue\n",
    "        try:\n",
    "            nshots_i = int(nshots_i)\n",
    "            rmse_i   = float(rmse_i)\n",
    "            std_i    = float(std_i)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        series.setdefault(method_i, []).append(\n",
    "            {\"Nshots\": nshots_i, \"rmse\": rmse_i, \"rmse_std\": std_i}\n",
    "        )\n",
    "\n",
    "# Deduplicate by (method, Nshots): keep latest\n",
    "for m, pts in list(series.items()):\n",
    "    by_n = {}\n",
    "    for p in pts:\n",
    "        by_n[p[\"Nshots\"]] = p\n",
    "    series[m] = sorted(by_n.values(), key=lambda d: d[\"Nshots\"])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Plot RMSE vs Nshots\n",
    "#    - Show error bars as points only (no global connecting lines)\n",
    "#    - Connect points with a dotted line ONLY for Nshots > 1000\n",
    "#    - Fit power law using only Nshots > 1000 and plot dotted fit\n",
    "#    - Logarithmic y-axis\n",
    "# ------------------------------------------------------------\n",
    "# Prepare/clear powerfit file header\n",
    "pf_header = \"run_root\\tmethod\\tA\\tc\\tn_points_fit\\tNmin_fit\"\n",
    "with open(powerfit_path, \"w\") as f:\n",
    "    f.write(pf_header + \"\\n\")\n",
    "\n",
    "plt.figure(figsize=(8.0, 5.0))\n",
    "\n",
    "for method_i, pts in series.items():\n",
    "    if not pts:\n",
    "        continue\n",
    "    xs_all = [p[\"Nshots\"] for p in pts]\n",
    "    ys_all = [p[\"rmse\"]   for p in pts]\n",
    "    es_all = [p[\"rmse_std\"] for p in pts]\n",
    "\n",
    "    # Plot all points with error bars (no connecting line)\n",
    "    plt.errorbar(xs_all, ys_all, yerr=es_all, fmt='o', capsize=4, linestyle='none', label=method_i)\n",
    "\n",
    "    # Connect only points with Nshots > 1000 using a dotted line\n",
    "    xs_gt = [x for x in xs_all if x > 999]\n",
    "    ys_gt = [y for x, y in zip(xs_all, ys_all) if x > 999]\n",
    "    if len(xs_gt) >= 2:\n",
    "        # Sort by Nshots to connect in order\n",
    "        order = np.argsort(xs_gt)\n",
    "        xs_gt_sorted = np.array(xs_gt)[order]\n",
    "        ys_gt_sorted = np.array(ys_gt)[order]\n",
    "        plt.plot(xs_gt_sorted, ys_gt_sorted, linestyle=\":\", marker=None)  # dotted connection for >1000 only\n",
    "\n",
    "    # ---- Power-law regression for Nshots > 1000: ε(N) = A / N^c ----\n",
    "    if len(xs_gt) >= 2 and all(y > 0 for y in ys_gt):\n",
    "        logX = np.log(xs_gt_sorted.astype(float))\n",
    "        logY = np.log(ys_gt_sorted.astype(float))\n",
    "        m, b = np.polyfit(logX, logY, 1)  # logY = m*logX + b  => A = e^b, c = -m\n",
    "        A = float(np.exp(b))\n",
    "        c = float(-m)\n",
    "\n",
    "        # Save fit params\n",
    "        with open(powerfit_path, \"a\") as pf:\n",
    "            pf.write(f\"{base_root}\\t{method_i}\\t{A:.8e}\\t{c:.8f}\\t{len(xs_gt_sorted)}\\t1000\\n\")\n",
    "\n",
    "        # Smooth fit curve over the >1000 range\n",
    "        x_fit = np.linspace(xs_gt_sorted.min(), xs_gt_sorted.max(), 200)\n",
    "        y_fit = A / (x_fit ** c)\n",
    "\n",
    "        # Plot the fit as a dotted line (overlay)\n",
    "        plt.plot(x_fit, y_fit, linestyle=\":\", label=f\"{method_i} fit (c={c:.2f})\")\n",
    "\n",
    "plt.xlabel(\"Number of shots (Nshots)\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(f\"RMSE vs Nshots for {base_root}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")# logarithmic vertical axis\n",
    "plt.grid(True, which=\"both\", axis=\"both\", linestyle=\"--\", alpha=0.7)\n",
    "plt.legend(title=\"Method\", ncol=1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(vs_plot_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Empirical benchmark: RMSE-vs-Nshots plot saved to {vs_plot_path}\")\n",
    "print(f\"Power-law fit parameters written to {powerfit_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e48d1c-af2f-4642-a201-13e66f889480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NEW CELL: Bar chart of c with std/uncertainty per method ---\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reuse your existing paths/vars:\n",
    "# - base_root, vs_txt_path, bar_dir should already exist in your session.\n",
    "# If not, set them accordingly before running this cell.\n",
    "\n",
    "# 1) Read series back (same as earlier, but lightweight)\n",
    "series = {}\n",
    "with open(vs_txt_path, \"r\") as f:\n",
    "    next(f, None)\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) != 7:\n",
    "            continue\n",
    "        run_root_i, method_i, nshots_i, rmse_i, std_i, _, _ = parts\n",
    "        if run_root_i != base_root:\n",
    "            continue\n",
    "        try:\n",
    "            nshots_i = int(nshots_i)\n",
    "            rmse_i   = float(rmse_i)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        series.setdefault(method_i, []).append({\"Nshots\": nshots_i, \"rmse\": rmse_i})\n",
    "\n",
    "# Deduplicate by Nshots and sort\n",
    "for m, pts in list(series.items()):\n",
    "    by_n = {}\n",
    "    for p in pts:\n",
    "        by_n[p[\"Nshots\"]] = p\n",
    "    series[m] = sorted(by_n.values(), key=lambda d: d[\"Nshots\"])\n",
    "\n",
    "# 2) For each method, fit log–log line for Nshots>1000 and compute slope SE\n",
    "def fit_c_with_se(xs, ys):\n",
    "    \"\"\"\n",
    "    Given arrays xs (Nshots) and ys (rmse), both > 0 and len>=2,\n",
    "    returns (c, se_c) where c = -slope(logY vs logX),\n",
    "    and se_c is the standard error of the slope (uncertainty of c).\n",
    "    \"\"\"\n",
    "    X = np.log(np.asarray(xs, dtype=float))\n",
    "    Y = np.log(np.asarray(ys, dtype=float))\n",
    "    n = X.size\n",
    "    if n < 2 or np.any(~np.isfinite(X)) or np.any(~np.isfinite(Y)):\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    # Linear regression Y = m X + b\n",
    "    m, b = np.polyfit(X, Y, 1)\n",
    "\n",
    "    # Standard error of slope m:\n",
    "    # se_m = sqrt( RSS / (n-2) / Sxx ), where RSS = sum(resid^2), Sxx = sum((X - Xbar)^2)\n",
    "    if n >= 3:\n",
    "        Yhat = m * X + b\n",
    "        resid = Y - Yhat\n",
    "        RSS = float(np.sum(resid**2))\n",
    "        Sxx = float(np.sum((X - X.mean())**2))\n",
    "        if Sxx > 0:\n",
    "            sigma2 = RSS / (n - 2)\n",
    "            se_m = np.sqrt(sigma2 / Sxx)\n",
    "        else:\n",
    "            se_m = np.nan\n",
    "    else:\n",
    "        # With only 2 points, no DOF for variance estimate; no SE available\n",
    "        se_m = np.nan\n",
    "\n",
    "    c = -m\n",
    "    se_c = se_m  # c = -m => same standard error\n",
    "    return float(c), float(se_c) if np.isfinite(se_m) else np.nan\n",
    "\n",
    "methods = []\n",
    "c_vals  = []\n",
    "c_errs  = []\n",
    "\n",
    "NMIN = 1000  # threshold for \"asymptotic\" fit region\n",
    "\n",
    "for method, pts in series.items():\n",
    "    xs_gt = [p[\"Nshots\"] for p in pts if p[\"Nshots\"] > NMIN and p[\"rmse\"] > 0]\n",
    "    ys_gt = [p[\"rmse\"]   for p in pts if p[\"Nshots\"] > NMIN and p[\"rmse\"] > 0]\n",
    "    if len(xs_gt) >= 2:\n",
    "        c, se_c = fit_c_with_se(xs_gt, ys_gt)\n",
    "        methods.append(method)\n",
    "        c_vals.append(c)\n",
    "        c_errs.append(se_c)\n",
    "    else:\n",
    "        # Not enough points to fit; include as NaN so you see it missing\n",
    "        methods.append(method)\n",
    "        c_vals.append(np.nan)\n",
    "        c_errs.append(np.nan)\n",
    "\n",
    "# 3) Plot a single bar chart with error bars (one bar per method)\n",
    "plt.figure(figsize=(7.5, 4.5))\n",
    "bars = plt.bar(methods, c_vals, yerr=c_errs, capsize=6)\n",
    "plt.ylabel(\"Exponent c (± SE)\")\n",
    "plt.title(f\"Power-law exponent c with uncertainty (> {NMIN} shots)\\n{base_root}\")\n",
    "plt.xticks(rotation=60, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save alongside your other empirical plots\n",
    "c_plot_path = os.path.join(bar_dir, base_root + \"_c_bar.png\")\n",
    "plt.savefig(c_plot_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Saved c bar chart with error bars to {c_plot_path}\")\n",
    "\n",
    "# --- Optional: if you truly want a separate (single-bar) plot per method, uncomment below ---\n",
    "for method, c, err in zip(methods, c_vals, c_errs):\n",
    "    plt.figure(figsize=(4.0, 3.2))\n",
    "    plt.bar([method], [c], yerr=[err], capsize=6)\n",
    "    plt.ylabel(\"Exponent c (± SE)\")\n",
    "    plt.title(f\"c for {method} (> {NMIN} shots)\")\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(bar_dir, f\"{base_root}_c_{method}.png\")\n",
    "    plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "    print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed6c26f-0601-469b-9711-9569d201f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- COMPLETE CELL: N required for chemical accuracy + log-scale bar chart with log-consistent error bars ---\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===============================\n",
    "# Config / Inputs already in env:\n",
    "#   base_root, vs_txt_path, bar_dir\n",
    "# If not defined, set them here.\n",
    "# ===============================\n",
    "\n",
    "# 0) Target accuracy (Hartree)\n",
    "epsilon_mHa = 1.6              # chemical accuracy in mHa\n",
    "epsilon     = epsilon_mHa * 1e-3  # convert to Hartree\n",
    "\n",
    "# 1) Read data back (per method)\n",
    "series = {}\n",
    "with open(vs_txt_path, \"r\") as f:\n",
    "    next(f, None)  # skip header\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) != 7:\n",
    "            continue\n",
    "        run_root_i, method_i, nshots_i, rmse_i, std_i, _, _ = parts\n",
    "        if run_root_i != base_root:\n",
    "            continue\n",
    "        try:\n",
    "            nshots_i = int(nshots_i)\n",
    "            rmse_i   = float(rmse_i)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        # Keep only positive RMSEs (log required)\n",
    "        if rmse_i > 0:\n",
    "            series.setdefault(method_i, []).append({\"Nshots\": nshots_i, \"rmse\": rmse_i})\n",
    "\n",
    "# Deduplicate by Nshots and sort\n",
    "for m, pts in list(series.items()):\n",
    "    by_n = {}\n",
    "    for p in pts:\n",
    "        by_n[p[\"Nshots\"]] = p\n",
    "    series[m] = sorted(by_n.values(), key=lambda d: d[\"Nshots\"])\n",
    "\n",
    "# 2) Fit log–log line (N>1000)\n",
    "#    log(rmse) = m * log(N) + b  =>  A = exp(b),  c = -m\n",
    "def fit_loglog_with_se(xs, ys):\n",
    "    X = np.log(np.asarray(xs, dtype=float))\n",
    "    Y = np.log(np.asarray(ys, dtype=float))\n",
    "    n = X.size\n",
    "    if n < 2 or not np.all(np.isfinite(X)) or not np.all(np.isfinite(Y)):\n",
    "        return np.nan, np.nan, np.nan, np.nan  # m, b, se_m, se_b\n",
    "\n",
    "    m, b = np.polyfit(X, Y, 1)\n",
    "\n",
    "    # OLS standard errors:\n",
    "    # se_m = sqrt( RSS / (n-2) / Sxx )\n",
    "    # se_b = sqrt( RSS / (n-2) * (1/n + Xbar^2 / Sxx) )\n",
    "    if n >= 3:\n",
    "        Yhat = m * X + b\n",
    "        resid = Y - Yhat\n",
    "        RSS = float(np.sum(resid**2))\n",
    "        Sxx = float(np.sum((X - X.mean())**2))\n",
    "        if Sxx > 0:\n",
    "            sigma2 = RSS / max(n - 2, 1)\n",
    "            se_m = np.sqrt(sigma2 / Sxx)\n",
    "            se_b = np.sqrt(sigma2 * (1.0/n + (X.mean()**2) / Sxx))\n",
    "        else:\n",
    "            se_m = np.nan\n",
    "            se_b = np.nan\n",
    "    else:\n",
    "        se_m = np.nan\n",
    "        se_b = np.nan\n",
    "\n",
    "    return float(m), float(b), float(se_m), float(se_b)\n",
    "\n",
    "NMIN = 1000\n",
    "\n",
    "methods, N_vals, N_errs = [], [], []\n",
    "\n",
    "for method, pts in series.items():\n",
    "    xs_gt = [p[\"Nshots\"] for p in pts if p[\"Nshots\"] > NMIN]\n",
    "    ys_gt = [p[\"rmse\"]   for p in pts if p[\"Nshots\"] > NMIN]\n",
    "\n",
    "    if len(xs_gt) >= 2 and all(y > 0 for y in ys_gt):\n",
    "        m, b, se_m, se_b = fit_loglog_with_se(xs_gt, ys_gt)\n",
    "        c = -m\n",
    "        A = np.exp(b)\n",
    "\n",
    "        # Uncertainties for A and c\n",
    "        dA = A * se_b if np.isfinite(se_b) else np.nan\n",
    "        dc = se_m      if np.isfinite(se_m) else np.nan\n",
    "\n",
    "        valid = np.isfinite(A) and np.isfinite(c) and (A > 0) and (c != 0) and (epsilon > 0)\n",
    "        if valid:\n",
    "            N_req = (A / epsilon) ** (1.0 / c)\n",
    "            if np.isfinite(N_req) and N_req > 0:\n",
    "                # Linear error propagation: ΔN = N/c * ΔA/A + N*log(N) * Δc/c\n",
    "                termA = (N_req / c) * (dA / A) if (np.isfinite(dA) and A > 0 and c != 0) else np.nan\n",
    "                termc = N_req * np.log(N_req) * (dc / c) if (np.isfinite(dc) and c != 0) else np.nan\n",
    "                dN = termA + termc\n",
    "                # Fallback if only one term is defined\n",
    "                if np.isnan(dN):\n",
    "                    if np.isfinite(termA) and not np.isfinite(termc):\n",
    "                        dN = termA\n",
    "                    elif np.isfinite(termc) and not np.isfinite(termA):\n",
    "                        dN = termc\n",
    "\n",
    "                # Ensure non-negative uncertainty\n",
    "                if np.isfinite(dN) and dN < 0:\n",
    "                    dN = abs(dN)\n",
    "\n",
    "                methods.append(method)\n",
    "                N_vals.append(float(N_req))\n",
    "                N_errs.append(float(dN) if np.isfinite(dN) else np.nan)\n",
    "                continue\n",
    "\n",
    "    # If not enough data / invalid fit, log as NaN so it's visible in the table\n",
    "    methods.append(method)\n",
    "    N_vals.append(np.nan)\n",
    "    N_errs.append(np.nan)\n",
    "\n",
    "# 3) Plot bar chart with log y-axis and log-consistent asymmetric error bars\n",
    "# Convert linear ΔN to log-space symmetric error, then back to asymmetric linear yerr\n",
    "lower_errs, upper_errs = [], []\n",
    "for val, err in zip(N_vals, N_errs):\n",
    "    if np.isfinite(val) and np.isfinite(err) and val > 0 and err > 0:\n",
    "        dlog = err / val                    # Δln N ≈ ΔN / N\n",
    "        lower = val - val * np.exp(-dlog)   # N - N*e^{-ΔlnN}\n",
    "        upper = val * np.exp(dlog) - val    # N*e^{ΔlnN} - N\n",
    "        # guard for tiny/negative numerical noise\n",
    "        lower_errs.append(max(lower, 0.0))\n",
    "        upper_errs.append(max(upper, 0.0))\n",
    "    else:\n",
    "        lower_errs.append(np.nan)\n",
    "        upper_errs.append(np.nan)\n",
    "\n",
    "yerr_asym = np.array([lower_errs, upper_errs])\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.bar(methods, N_vals, yerr=yerr_asym, capsize=6)\n",
    "plt.ylabel(\"Shots N for chemical accuracy\")\n",
    "plt.title(f\"N to reach ε = {epsilon_mHa} mHa (base: {base_root})\")\n",
    "plt.xticks(rotation=60, ha=\"right\")\n",
    "plt.yscale(\"log\")  # logarithmic y-axis\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7, which=\"both\")\n",
    "plt.tight_layout()\n",
    "\n",
    "out_path = os.path.join(bar_dir, f\"{base_root}_N_for_chem_accuracy_log.png\")\n",
    "plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Saved bar chart of N (± ΔN) [log axis & log-consistent errors] to {out_path}\")\n",
    "\n",
    "# 4) Print a compact table\n",
    "print(\"\\nEstimated N for chemical accuracy:\")\n",
    "for mth, nval, nerr in zip(methods, N_vals, N_errs):\n",
    "    if np.isfinite(nval):\n",
    "        if np.isfinite(nerr):\n",
    "            print(f\"  {mth:20s} N ≈ {nval:.3e}  ± {nerr:.2e}\")\n",
    "        else:\n",
    "            print(f\"  {mth:20s} N ≈ {nval:.3e}  (uncertainty unavailable)\")\n",
    "    else:\n",
    "        print(f\"  {mth:20s} N: unavailable (insufficient data for fit)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649c3a5-88aa-4e3d-b9fc-6626446f546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# ------------------ Paths ------------------\n",
    "save_dir = os.path.join(savepath, \"bound_plots\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "log_path = os.path.join(\n",
    "    save_dir,\n",
    "    savename.format(\"all_methods\").replace(\".txt\", \"\") + \"_log.txt\"\n",
    ")\n",
    "\n",
    "# ------------------ Save current method results ------------------\n",
    "clean_method = str(method).split('.')[-1].split(' ')[0].replace('<', '').replace('>', '')\n",
    "\n",
    "with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"# METHOD: {clean_method}\\n\")\n",
    "    f.write(f\"# Nshots: {Nrounds}\\n\")\n",
    "    for r, v in zip(estimator.measurement_scheme.rounds,\n",
    "                    estimator.measurement_scheme.inconfidence):\n",
    "        f.write(f\"{r}\\t{v}\\n\")\n",
    "    f.write(\"\\n\")  # blank line to separate methods\n",
    "\n",
    "print(f\"Appended results for method '{clean_method}' to {log_path}\")\n",
    "\n",
    "# ------------------ Keep only newest block per method (in place) ------------------\n",
    "def keep_latest_per_method_inplace(path: str) -> None:\n",
    "    \"\"\"\n",
    "    Rewrite `path` so only the latest block per method remains.\n",
    "    Block format:\n",
    "      # METHOD: <name>\n",
    "      # Nshots: <...>\n",
    "      <round>\\t<value>\n",
    "      ...\n",
    "      <blank line> (optional at EOF)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        return\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    blocks = []  # (method, start_idx, end_idx)\n",
    "    current_method, start_idx = None, None\n",
    "\n",
    "    def close_block(end_idx: int):\n",
    "        nonlocal current_method, start_idx\n",
    "        if current_method is not None and start_idx is not None:\n",
    "            blocks.append((current_method, start_idx, end_idx))\n",
    "        current_method, start_idx = None, None\n",
    "\n",
    "    for i, raw in enumerate(lines):\n",
    "        s = raw.strip()\n",
    "        if s.startswith(\"# METHOD:\"):\n",
    "            close_block(i)\n",
    "            current_method = raw.split(\":\", 1)[1].strip()\n",
    "            start_idx = i\n",
    "        elif s == \"\" and current_method is not None:\n",
    "            close_block(i + 1)\n",
    "    close_block(len(lines))  # flush last block if file ended without blank line\n",
    "\n",
    "    if not blocks:\n",
    "        return\n",
    "\n",
    "    # Keep only the last occurrence for each method\n",
    "    last_idx_for_method = {}\n",
    "    for idx, (m, _, _) in enumerate(blocks):\n",
    "        last_idx_for_method[m] = idx  # overwrite => last wins\n",
    "\n",
    "    # Preserve file-order of last appearances\n",
    "    keep_indices = sorted(last_idx_for_method.values(), key=lambda i: blocks[i][1])\n",
    "    kept_spans = [(blocks[i][1], blocks[i][2]) for i in keep_indices]\n",
    "\n",
    "    new_lines = []\n",
    "    for s, e in kept_spans:\n",
    "        if new_lines and new_lines[-1].strip() != \"\":\n",
    "            new_lines.append(\"\\n\")\n",
    "        new_lines.extend(lines[s:e])\n",
    "\n",
    "    if new_lines and not new_lines[-1].endswith(\"\\n\"):\n",
    "        new_lines[-1] += \"\\n\"\n",
    "\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(new_lines)\n",
    "\n",
    "# Deduplicate log now\n",
    "keep_latest_per_method_inplace(log_path)\n",
    "\n",
    "# ------------------ Read all results from (deduped) file ------------------\n",
    "data = defaultdict(lambda: {\"rounds\": [], \"vals\": []})\n",
    "current_method = None\n",
    "\n",
    "with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        if line.startswith(\"# METHOD:\"):\n",
    "            current_method = line.split(\":\", 1)[1].strip()\n",
    "        elif line.startswith(\"#\"):\n",
    "            continue  # skip comments/metadata\n",
    "        elif current_method is not None:\n",
    "            try:\n",
    "                r_str, v_str = line.split()\n",
    "                data[current_method][\"rounds\"].append(float(r_str))\n",
    "                data[current_method][\"vals\"].append(float(v_str))\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "# ------------------ Plot all methods (latest run only, no markers) ------------------\n",
    "plt.figure(\"Inconfidence Bound evolution\", clear=True)\n",
    "for m, series in data.items():\n",
    "    if series[\"rounds\"]:\n",
    "        x = np.asarray(series[\"rounds\"], dtype=float)\n",
    "        y = np.asarray(series[\"vals\"], dtype=float)\n",
    "        order = np.argsort(x)  # ensure clean monotone x\n",
    "        plt.plot(x[order], y[order], label=m)  # lines only\n",
    "\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Inconfidence Bound\")\n",
    "plt.title(\"Inconfidence Bound over rounds (latest run per method)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "combined_plot = os.path.join(\n",
    "    save_dir,\n",
    "    savename.format(\"combined_from_log\").replace(\".txt\", \"\") + f\"Nshots={Nrounds}.png\"\n",
    ")\n",
    "plt.savefig(combined_plot, dpi=150, bbox_inches=\"tight\")\n",
    "print(f\"Combined plot saved to {combined_plot}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bb01e7-3de2-4f02-8c30-a99e3685b661",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# u"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
