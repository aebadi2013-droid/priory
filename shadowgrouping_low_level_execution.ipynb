{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867122f7-65d5-4216-81b5-a583992d4121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import isdir, isfile\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from decimal import Decimal\n",
    "\n",
    "# adding ShadowGrouping package to the system path\n",
    "# SG_package_path = r\"C:\\\\Users\\\\bpmur\\\\OneDrive\\\\Microsoft Teams Chat Files\\\\Documents\\\\Work\\\\Research\\\\Numerics\\\\ShadowGrouping Code\\\\\"\n",
    "SG_package_path = r\"C:\\\\Users\\\\Bruno Murta\\\\OneDrive\\\\Microsoft Teams Chat Files\\\\Documents\\\\Work\\\\Research\\\\Numerics\\\\ShadowGrouping Code\\\\\"\n",
    "sys.path.insert(0, SG_package_path)\n",
    "\n",
    "# defining path of folder where molecular Hamiltonians are stored\n",
    "folder_Hamiltonians = SG_package_path + \"Hamiltonians\\\\\"\n",
    "\n",
    "# defining path where OGM probabilities are stored\n",
    "folder_OGM_settings = SG_package_path + \"OGM_probabilities\\\\OGM_{}_{}{}.txt\" # format string to fill in {molecule}x{qubit_number}x{mapping}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c72991a-7d56-4894-b3a1-a338704ead49",
   "metadata": {},
   "source": [
    "Importing original version of ShadowGrouping code (v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c381ecb1-16ad-40f9-b26f-1da052b412f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the measurement schemes from the Benchmark\n",
    "from shadowgrouping.measurement_schemes import Shadow_Grouping, Derandomization, AdaptiveShadows, L1_sampler, hit_by, N_delta\n",
    "from shadowgrouping.measurement_schemes_Shadowupdate import Shadow_Grouping_Update, Shadow_Grouping_Update2, Shadow_Grouping_Update3, Shadow_Grouping_Update4, Shadow_Grouping_Update6, Shadow_Grouping_Update7\n",
    "from shadowgrouping.measurement_schemes import SettingSampler as Overlapped_Grouping\n",
    "from shadowgrouping.AEQuO import AEQuO\n",
    "from shadowgrouping.weight_functions import Inconfidence_bound, Bernstein_bound\n",
    "\n",
    "# wrapper class to combine the measurement scheme with the respective outcomes\n",
    "from shadowgrouping.energy_estimator import Energy_estimator, StateSampler, Sign_estimator\n",
    "\n",
    "# helper functions to load Hamiltonian decompositions\n",
    "from shadowgrouping.measurement_schemes import setting_to_str\n",
    "from shadowgrouping.hamiltonian import get_pauli_list, get_groundstate, char_to_int, int_to_char, mappings, load_pauli_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3078d5d-116a-42c8-a9de-1370b288b4a5",
   "metadata": {},
   "source": [
    "Choosing molecule, basis set and fermion-to-qubit mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76746bd7-11d3-4e2d-a7ad-7b61e1ceb5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule_name = \"LiH\" # choose one out of the molecules ['H2', 'H2_6-31g', 'LiH', 'BeH2', 'H2O', 'NH3']\n",
    "mapping_name = \"JW\" # choose one out of [\"JW\",\"BK\",\"Parity\"]\n",
    "basis_set = \"sto3g\" # choose one out of [\"sto3g\",\"6-31g\"] - the latter only for H2 molecule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a0e15c-4e07-4e9a-b49d-266052fee6f1",
   "metadata": {},
   "source": [
    "Obtaining Pauli decomposition of Hamiltonian and its exact ground state from saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07788ac-99ee-413f-b060-599949e72843",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\\\\\Users\\\\\\\\Bruno Murta\\\\\\\\OneDrive\\\\\\\\Microsoft Teams Chat Files\\\\\\\\Documents\\\\\\\\Work\\\\\\\\Research\\\\\\\\Numerics\\\\\\\\ShadowGrouping Code\\\\\\\\Hamiltonians\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m observables, w, offset, E_GS, state \u001b[38;5;241m=\u001b[39m load_pauli_list(folder_Hamiltonians,molecule_name,basis_set,mapping_name,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\shadowgrouping\\shadowgrouping\\hamiltonian.py:98\u001b[0m, in \u001b[0;36mload_pauli_list\u001b[1;34m(folder_hamiltonian, molecule_name, basis_name, encoding, verbose, sparse, diagonalize)\u001b[0m\n\u001b[0;32m     95\u001b[0m len_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(molecule_name) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(basis_name) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# for underscore char in naming scheme\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# open folder where the Hamiltonians of various encodings are stored\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m available_folders \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(folder_hamiltonian)\n\u001b[0;32m     99\u001b[0m folder_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m available_folders:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\\\\\Users\\\\\\\\Bruno Murta\\\\\\\\OneDrive\\\\\\\\Microsoft Teams Chat Files\\\\\\\\Documents\\\\\\\\Work\\\\\\\\Research\\\\\\\\Numerics\\\\\\\\ShadowGrouping Code\\\\\\\\Hamiltonians\\\\'"
     ]
    }
   ],
   "source": [
    "observables, w, offset, E_GS, state = load_pauli_list(folder_Hamiltonians,molecule_name,basis_set,mapping_name,verbose=True,sparse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b677e-cfef-4c42-b80a-2f30bba5f295",
   "metadata": {},
   "source": [
    "Initializing 'method' that will generate measurement scheme to estimate the energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b50086-2b23-44a4-85c7-d74f531b27c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_init(method_name, molecule_name, mapping_name, observables, w, offset, eps):\n",
    "    if method_name == 'ShadowGrouping':\n",
    "        alpha = np.max(np.abs(w))/np.min(np.abs(w)) + np.min(np.abs(w))\n",
    "        method = Shadow_Grouping(observables,w,eps,Bernstein_bound(alpha=alpha)())\n",
    "    elif method_name == 'Derandomization':\n",
    "        method = Derandomization(observables,w,np.sqrt(0.9),use_one_norm=True)\n",
    "    elif method_name == 'RandomPaulis':\n",
    "        method = Derandomization(observables,w,eps,delta=1) # delta controls the randomness\n",
    "    elif method_name == 'AdaptivePaulis':\n",
    "        method = AdaptiveShadows(observables,w)\n",
    "    elif method_name == 'AEQuO':\n",
    "        # values from figure 5 (L == adaptiveness_L +1) of https://arxiv.org/abs/2110.15339\n",
    "        method = AEQuO(observables,w,offset,adaptiveness_L=2,interval_skewness_l=4,budget=1000)\n",
    "    elif method_name == 'OverlappedGrouping':\n",
    "        # catch exception of missing data for OGM\n",
    "        file = folder_OGM_settings.format(molecule_name,observables.shape[1],mapping_name.lower())\n",
    "        if isfile(file):\n",
    "            method = Overlapped_Grouping(observables,w,file)\n",
    "    else:\n",
    "        print('method_name provided is invalid.')\n",
    "        return False\n",
    "\n",
    "    return method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02091be4-9cc8-44cf-aaf3-d93a52e302c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_name = 'ShadowGrouping'\n",
    "method = method_init(method_name, molecule_name, mapping_name, observables, w, offset, eps=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a9cd49-b309-4698-8abe-f46111aa9814",
   "metadata": {},
   "source": [
    "Initializing 'estimator', which executes the three key parts:\n",
    "\n",
    "1. generation of measurement settings via 'propose_next_settings', which calls find_setting from chosen 'measurement_scheme' method\n",
    "2. sampling of reference state via StateSampler\n",
    "3. computation of energy via its own 'measure' and 'get_energy' functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72bc1c60-f790-444f-9d67-d905d38db470",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Energy_estimator(method,StateSampler(state),offset=offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f85a73-3504-450e-8d52-40f826d822eb",
   "metadata": {},
   "source": [
    "Printing the number of observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f1b5804-708c-4359-9fa9-c82d78449941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\n"
     ]
    }
   ],
   "source": [
    "print(len(observables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11758392-a4a5-4661-8af3-9281e010d721",
   "metadata": {},
   "source": [
    "Generating measurement scheme with N_rounds and printing number of occurrences of each setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea90a1f1-e8a1-4863-b417-9cca1705b338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'XXXXXXXXYYYY': 1, 'XXXXYYYYXXXX': 1, 'XXXZZXXZXZZX': 1, 'XXXZZXXZZZZX': 1, 'XXXZZXYYZZZY': 1, 'XXYZZYYZYZZY': 1, 'XXZXXZZZXXXZ': 1, 'XXZZZXXXXZZX': 1, 'XXZZZXZXZZZX': 1, 'XXZZZXZYYZZY': 1, 'XXZZZZYZZZZY': 1, 'XYYZZXYYXZZX': 1, 'XZXZXXXZXZXX': 1, 'XZXZXZXXZZXZ': 1, 'XZXZXZYYZZYZ': 1, 'XZXZZXYZYZZY': 1, 'XZXZZXZXXZZX': 1, 'XZXZZZXYYZZX': 1, 'XZXZZZXZZZZX': 1, 'XZXZZZYZZZZY': 1, 'XZXZZZZXZZZX': 1, 'XZXZZZZYZZZY': 1, 'XZZXZXZZXXZX': 1, 'XZZXZZXZZXZZ': 1, 'XZZXZZYZZYZZ': 1, 'XZZXZZZXZXZZ': 1, 'XZZXZZZYZYZZ': 1, 'XZZXZZZZYYZY': 1, 'XZZZXZXZZZXZ': 1, 'XZZZXZYZZZYZ': 1, 'XZZZXZZXZZXZ': 1, 'XZZZXZZYZZYZ': 1, 'XZZZXZZZXZXX': 1, 'XZZZXZZZYZYY': 1, 'XZZZZXXXXZZX': 1, 'XZZZZXXZXZZZ': 1, 'XZZZZXXZZZZX': 1, 'XZZZZXYYZZZZ': 1, 'XZZZZXYZYZZZ': 1, 'XZZZZXYZZZZY': 1, 'XZZZZXZXZZZX': 1, 'XZZZZXZYYZZY': 1, 'XZZZZXZYZZZY': 1, 'YXXZZYXXYZZY': 1, 'YYXZXXYZYZYY': 1, 'YYXZZXXZZZZX': 1, 'YYYYZYXZXXZX': 1, 'YYYYZYYYYYZY': 1, 'YYYZYYXXXZXX': 1, 'YYYZZYXXZZZX': 1, 'YYYZZYYZZZZY': 1, 'YYYZZYZXXZZZ': 1, 'YYZYYZXZXXXZ': 1, 'YYZZZYXXXZZX': 1, 'YYZZZYYYYZZY': 1, 'YYZZZYZYZZZY': 1, 'YZYYZZXXZXZZ': 1, 'YZYZYYYZYZYY': 1, 'YZYZYZYYZZYZ': 1, 'YZYZZYXZXZZX': 1, 'YZYZZYZYYZZY': 1, 'YZYZZZXZZZZX': 1, 'YZYZZZYXXZZY': 1, 'YZYZZZYZZZZY': 1, 'YZYZZZZXZZZX': 1, 'YZYZZZZYZZZY': 1, 'YZZYZZXZZXZZ': 1, 'YZZYZZYZZYZZ': 1, 'YZZYZZZXZXZZ': 1, 'YZZYZZZYZYZZ': 1, 'YZZYZZZZXXZX': 1, 'YZZYZZZZYYZY': 1, 'YZZZYZXZZZXZ': 1, 'YZZZYZYZZZYZ': 1, 'YZZZYZZXXZXX': 1, 'YZZZYZZXZZXZ': 1, 'YZZZYZZYZZYZ': 1, 'YZZZYZZZYZYY': 1, 'YZZZZYXXZZZZ': 1, 'YZZZZYXZXZZZ': 1, 'YZZZZYXZZZZX': 1, 'YZZZZYYYYZZY': 1, 'YZZZZYYZYZZZ': 1, 'YZZZZYYZZZZY': 1, 'YZZZZYZXXZZX': 1, 'YZZZZYZXZZZX': 1, 'YZZZZYZYZZZY': 1, 'ZXXZZXXXZZZX': 1, 'ZXXZZXYZYZZZ': 1, 'ZXXZZXYZZZZY': 1, 'ZXXZZXZYYZZZ': 1, 'ZXXZZZZXXZZX': 1, 'ZXZXZXZXZXZX': 1, 'ZXZXZXZYZYZY': 1, 'ZXZXZXZZYYZZ': 1, 'ZXZXZZXZZXZZ': 1, 'ZXZXZZYZZYZZ': 1, 'ZXZZXXZXZZXX': 1, 'ZXZZXXZYZZYY': 1, 'ZXZZXZXZZZXZ': 1, 'ZXZZXZYZZZYZ': 1, 'ZXZZXZZZXZXZ': 1, 'ZXZZXZZZYZYZ': 1, 'ZXZZZXXZXZZZ': 1, 'ZXZZZXXZZZZX': 1, 'ZXZZZXYYZZZY': 1, 'ZXZZZXYZYZZZ': 1, 'ZXZZZXYZZZZY': 1, 'ZYYZZYXZZZZX': 1, 'ZYYZZYYYZZZY': 1, 'ZYYZZYYZYZZZ': 1, 'ZYYZZZYYYZZY': 1, 'ZYZYYZZZYYYZ': 1, 'ZYZYZYZXZXZX': 1, 'ZYZYZYZYZYZY': 1, 'ZYZYZZXZZXZZ': 1, 'ZYZYZZYZZYZZ': 1, 'ZYZZYYZXZZXX': 1, 'ZYZZYYZYZZYY': 1, 'ZYZZYZXZZZXZ': 1, 'ZYZZYZYZYZYZ': 1, 'ZYZZYZYZZZYZ': 1, 'ZYZZYZZZXZXZ': 1, 'ZYZZZYXXZZZX': 1, 'ZYZZZYXZXZZZ': 1, 'ZYZZZYXZZZZX': 1, 'ZYZZZYYZYZZZ': 1, 'ZYZZZYYZZZZY': 1, 'ZYZZZYZYZZZY': 1, 'ZZXXZXXZZXZZ': 1, 'ZZXXZXYZZYZZ': 1, 'ZZXXZZZXZXZX': 1, 'ZZXXZZZYZYZY': 1, 'ZZXZXXXZZZXZ': 1, 'ZZXZXXYZZZYZ': 1, 'ZZYYZYXZZXZZ': 1, 'ZZYYZYYZZYZZ': 1, 'ZZYYZZZYZYZZ': 1, 'ZZYZYYXZZZXZ': 1, 'ZZYZYYYZZZYZ': 1, 'ZZYZYZZXZZXZ': 1, 'ZZZZZZZZZZZZ': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator.reset()\n",
    "N_rounds = 142\n",
    "estimator.propose_next_settings(N_rounds)\n",
    "# version 1\n",
    "print(estimator.settings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bb221b-3769-4f7f-9b67-4b4cf8d6eeef",
   "metadata": {},
   "source": [
    "Printing the number of measurement rounds, total number of samples, number of observables, and number of samples per observable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7188daea-8242-4eb1-874c-855805641ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of measurement rounds:  142\n",
      "Total number of distinct measurement settings:  142\n",
      "Total number of samples across all observables:  6066\n",
      "Total number of observables:  630\n",
      "Number of samples for each observable\n",
      "[ 55  11  12   9   9  11  11   9   8  10  10  75  85 106   9  10 101  54\n",
      "  12  12  60  11   9   9   9  76   9  10   9   8  86 106   9   9 101  61\n",
      "   3   3   1   1   1   1   1   1   1   1   3   1   1   1   1   3  11  11\n",
      "   1   1   1   1   8   7   9   8   7   7   1   1   1   1   1   1   9   8\n",
      "   9  10   1   1   1   1   9   9   5   6   1   2   1   1   2   2   3   2\n",
      "   1   1   1   1  12  12   3   3   2   3   2   2  13   1   1   1   1   1\n",
      "   1   1   1   9  10   1   1   1   1   1   1   1   1  40   1   1   1   1\n",
      "  37  35  20   1   1   1   1   8   7   4   5   5   5   1   1   1   1  34\n",
      "   4   4   3   2  38   4   4   1   1   1   1  32   9   8  38   1   2   1\n",
      "   1   1   1   2   3   1   1   9  10  16  15   1   1   1   1   1   1   1\n",
      "   1   9   9   4   5   1   1   1   1   4   4   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1  37   9   8   6   6   9   9   2   2\n",
      "   5   2   5   5   3   4   1   2   1   1   2   3   2   1   3   3  21   3\n",
      "   3  43   2   2  55  53  42  10   9   9   9  15  15   1   1  11  11  11\n",
      "  10  33   2   2   1   2   2   4   3   2   4   4   4   4   2   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   4   4   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1  40   4   4   4   4   5   4   2   2   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   4\n",
      "   4   1   2   1   1  51   5   4   1   1   1   1   4   4   1   1   1   1\n",
      "   1   1   2   1   4   4   1   1   1   1   9   8  55   1   1   1   1   9\n",
      "   9   9   8  10   9  53   1   1   1   1  37   2   2   2   2  61  58  40\n",
      "  13  12  13  14  41   2   2   1   1   1   1   5   4   5   5   1   2   1\n",
      "   2   1   1   1   1   4   5   1   1   1   1   1   1   2   1  49   5   6\n",
      "   5   4   1   1   1   1   1   1   1   1   1   1   1   1   4   5   1   1\n",
      "   1   1  53   4   5   1   1   1   1   1   1   1   1   4   4   1   2   2\n",
      "   1  61   9  10   1   1   1   1  58   1   1   1   1   9  10   2   2  43\n",
      "  70  38  36   7  11  10  10   1   1   1   1   9   9  55  10   8   1   1\n",
      "   1   1   8   9   1   1   1   1  62   9   9   1   1   1   1 106   2   2\n",
      "   2   1  70  39  33  36   9   9   7   8   1   1   1   1   9   9   8   9\n",
      "  51   8   9   1   1   1   1  62   9   9   1   1   1   1  70 101   3   2\n",
      "   2   3  34  30   2   3   1   1   2   3  35   3   2   2   2  42   1   1\n",
      "  38  33  38  14   4   5  32   3   3   6   5  36  36  19  15  13   6   6\n",
      "  12  12  10  10   9   9   3   1   1   1   1   3   3   3  11  11   8   7\n",
      "  11   7   7   5   9   9   9   9  43  51  55   2   2  43  15  14   8  10\n",
      "   9   8   1   1  12  11  11  10  62  62  41  12  12  13  13  70  39  34]\n"
     ]
    }
   ],
   "source": [
    "print('Total number of measurement rounds: ', estimator.num_settings)\n",
    "print('Total number of distinct measurement settings: ', len(estimator.settings_dict))\n",
    "N_samples = np.sum(np.array(estimator.measurement_scheme.N_hits))\n",
    "print('Total number of samples across all observables: ', N_samples)\n",
    "print('Total number of observables: ', len(observables))\n",
    "print('Number of samples for each observable')\n",
    "print(estimator.measurement_scheme.N_hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aedb2ac-ea91-467a-8a0d-f5efbd40ff77",
   "metadata": {},
   "source": [
    "Determining number of observables without any sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b117954-68ed-4e92-b6fc-a021ee34cdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(np.where(estimator.measurement_scheme.N_hits == 0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230c89ff-dd51-4f39-ba03-c51bd3a75854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd215e0-41a5-455e-ba24-f11fd0a95726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
